# временные предложения

[04.25.2020 21:52]
вот термины, которые они используют в машинном обучении:

# Любит/не любит
- loss - насколько предсказание отличается от нужного результата. В случае для списка пар `(x, y)` часто используется среднеквадратичная ошибка. Пусть `y` — это судьбой предначертанное в зависимости от `x`. Пусть `f(x)` пытается угадать, какая судьба `y` ожидаеет `x`, `square` возводит число в квадрат, тогда `square(f(x) - y)` показывает насколько вангование точно (если 0 — значит сбудется, чем больше это число — тем хуже ванга `f(x)` нагадала для `y`). Задача машинного обучния — сделать вангование более точным, в этих терминах нужно сделать `square(f(x) - y)` как можно меньше. Для двух пар данных `(x1, y1) (x2, y2)` будет так: `square(f(x1) - y1) + square(f(x2) - y2)` - чем меньше это число, тем точнее прогноз для двух примеров. Для `N` пар данных будете так:
```ts
const loss = (x: number, y: number): number => square(f(x) - y)
const sum = (list: number[]): number => list.reduce((acc, element) => acc + element, 0)

const lossAll = sum([[x1, y1], [x2, y2], ..., [x, y]].map(([x, y]) => loss(x, y)))
// хочется, чтобы lossAll стал близко к 0
```

что такое градиент, градиентный спуск (куда что спускается?)

